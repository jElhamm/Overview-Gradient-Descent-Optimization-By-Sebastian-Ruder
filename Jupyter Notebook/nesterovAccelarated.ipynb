{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0C5Xga1x/iaVZnmCQ0F6F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# This code implements the Nesterov_Accelarated_Gradient optimization algorithm based on the cost function provided by the user.\n","\n","\n","import sys\n","import numpy as np\n","import scipy as sc\n","from sympy import Symbol, diff, lambdify, sympify, N"],"metadata":{"id":"kD1rRrmt-kUw","executionInfo":{"status":"ok","timestamp":1702820416770,"user_tz":-210,"elapsed":7,"user":{"displayName":"Elham Jafari","userId":"09412467550778604481"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def nesterovAcceleratedGradient(cost_function, function):\n","    x = Symbol('x')\n","    print(\"f(x) =\", cost_function)\n","    function_derivative = diff(cost_function, x)\n","    print(\"df(x)/dx =\", function_derivative)\n","    initialApproximation = float(input(\"\\n---> Enter initial approximation: \"))\n","    learningRate = float(input(\"---> Enter learning rate: \"))\n","    momentumConstant = float(input(\"---> Enter momentum constant: \"))\n","    errorTolerance = float(input(\"---> Enter error tolerance: \"))\n","    print(\"\\n---------------------------------------------------------------\")\n","    print(\" *** Starting Nesterov Accelerated Gradient\")\n","    print(\"        --->  x0 =\", initialApproximation)\n","    print(\"        --->  f(x0) =\", function(initialApproximation))\n","\n","    #----------------------------------------------------------------------------------------------------------------------------------------------------\n","    iterationCount = 0\n","    current_x = initialApproximation\n","    currentVelocity = 0\n","    while True:\n","        iterationCount += 1\n","        functionDerivativeValue = lambdify(x, function_derivative, \"numpy\")(current_x -momentumConstant * currentVelocity)\n","        updatedVelocity = momentumConstant * currentVelocity + learningRate * functionDerivativeValue\n","        current_x = current_x - updatedVelocity\n","\n","        if abs(N(current_x - initialApproximation)) < errorTolerance:\n","            break\n","\n","        initialApproximation = current_x\n","        currentVelocity = updatedVelocity\n","    #----------------------------------------------------------------------------------------------------------------------------------------------------\n","\n","    print(\" *** Number of Iterations =\", iterationCount)\n","    print(\"        --->  Minima is at =\", current_x)\n","    print(\"        --->  Minimum value of Cost Function =\", function(current_x))\n","    print(\"---------------------------------------------------------------\\n\")"],"metadata":{"id":"NhhMZuzC-mil","executionInfo":{"status":"ok","timestamp":1702820420511,"user_tz":-210,"elapsed":7,"user":{"displayName":"Elham Jafari","userId":"09412467550778604481"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Code execution section\n","\n","def main():\n","  x = Symbol('x')\n","  costFunction = input(\"---> Enter cost function f(x): \").strip()\n","  costFunctionSympy = sympify(costFunction)\n","  costFunctionNumpy = lambdify(x, costFunctionSympy, \"numpy\")\n","  nesterovAcceleratedGradient(costFunctionSympy, costFunctionNumpy)\n","\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gnC4EpZx-pFj","executionInfo":{"status":"ok","timestamp":1702820436243,"user_tz":-210,"elapsed":13998,"user":{"displayName":"Elham Jafari","userId":"09412467550778604481"}},"outputId":"fa1bffae-6b65-4132-f0aa-f278fdbc4582"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["---> Enter cost function f(x): x**3 - 2*x**2 + 4\n","f(x) = x**3 - 2*x**2 + 4\n","df(x)/dx = 3*x**2 - 4*x\n","\n","---> Enter initial approximation: 0\n","---> Enter learning rate: 0.1\n","---> Enter momentum constant: 0.9\n","---> Enter error tolerance: 0.01\n","\n","---------------------------------------------------------------\n"," *** Starting Nesterov Accelerated Gradient\n","        --->  x0 = 0.0\n","        --->  f(x0) = 4.0\n"," *** Number of Iterations = 1\n","        --->  Minima is at = 0.0\n","        --->  Minimum value of Cost Function = 4.0\n","---------------------------------------------------------------\n","\n"]}]}]}